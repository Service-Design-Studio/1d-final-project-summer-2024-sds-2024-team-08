{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanle\\AppData\\Local\\Temp\\ipykernel_13936\\1082291676.py:316: LangGraphDeprecationWarning: Parameter 'messages_modifier' in function 'create_react_agent' is deprecated as of version 0.1.9 and will be removed in version 0.2.0. Use 'state_modifier' parameter instead.\n",
      "  graph = create_react_agent(model, tools=tools, messages_modifier=SystemMessage(content=messages_modifier), checkpointer=PostgreSQLMemorySaver(engine=user_engine))\n",
      "Expected content to be a str, got a list with > 1 element.Merging values together\n",
      "Expected content to be a str, got a list with > 1 element.Merging values together\n",
      "Expected content to be a str, got a list with > 1 element.Merging values together\n",
      "Expected content to be a str, got a list with > 1 element.Merging values together\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\grpc\\_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1175\u001b[0m (\n\u001b[0;32m   1176\u001b[0m     state,\n\u001b[0;32m   1177\u001b[0m     call,\n\u001b[0;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1180\u001b[0m )\n\u001b[1;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\grpc\\_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:74.125.24.95:443 {grpc_message:\"Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\", grpc_status:8, created_time:\"2024-07-26T06:00:17.356262+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 344\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response_str\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mquery_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenerate a network graph to show the relationships Joe Biden has. Exclude all the relationships that includes stakeholders giving Joe Biden grants.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[31], line 325\u001b[0m, in \u001b[0;36mquery_model\u001b[1;34m(query, user_id, chat_id)\u001b[0m\n\u001b[0;32m    317\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    318\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, query)\n\u001b[0;32m    319\u001b[0m     ]}\n\u001b[0;32m    321\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m'\u001b[39m: chat_id}\n\u001b[0;32m    323\u001b[0m }\n\u001b[1;32m--> 325\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Stream mode set to updates instead of values for less verbosity\u001b[39;00m\n\u001b[0;32m    326\u001b[0m response_str \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m#  insert graph shit into Messages \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1668\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1666\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1667\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1668\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1111\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m-> 1111\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1758\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(done, inflight, step, timeout_exc_cls)\u001b[0m\n\u001b[0;32m   1756\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m   1757\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m-> 1758\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m   1760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m   1761\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m   1762\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m   1763\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langgraph\\pregel\\executor.py:43\u001b[0m, in \u001b[0;36mBackgroundExecutor.<locals>.done\u001b[1;34m(task)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:25\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     23\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2871\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2867\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m   2868\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2869\u001b[0m )\n\u001b[0;32m   2870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2871\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2873\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4436\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[0;32m   4423\u001b[0m \n\u001b[0;32m   4424\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4433\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[0;32m   4434\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4437\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4438\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4439\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4440\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   4444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4445\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4446\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1783\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1780\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1781\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1782\u001b[0m         Output,\n\u001b[1;32m-> 1783\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1785\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1790\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1791\u001b[0m     )\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1793\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:383\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    382\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4292\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   4290\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   4291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4292\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   4294\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4295\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[0;32m   4296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:383\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    382\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:579\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.call_model\u001b[1;34m(state, config)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_model\u001b[39m(\n\u001b[0;32m    576\u001b[0m     state: AgentState,\n\u001b[0;32m    577\u001b[0m     config: RunnableConfig,\n\u001b[0;32m    578\u001b[0m ):\n\u001b[1;32m--> 579\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_runnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last_step\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtool_calls:\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    582\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    583\u001b[0m                 AIMessage(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    587\u001b[0m             ]\n\u001b[0;32m    588\u001b[0m         }\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2873\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2871\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2872\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2873\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2874\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2875\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5055\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5050\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5051\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5052\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5053\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5054\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5056\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5057\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5058\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5059\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:265\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    262\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    264\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 265\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    275\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:698\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    692\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    696\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    697\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:555\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    554\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 555\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    556\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    557\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    559\u001b[0m ]\n\u001b[0;32m    560\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:545\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    544\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 545\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m         )\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:770\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 770\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    774\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_google_vertexai\\chat_models.py:1100\u001b[0m, in \u001b[0;36mChatVertexAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_gemini_model:\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_non_gemini(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_gemini\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_google_vertexai\\chat_models.py:1190\u001b[0m, in \u001b[0;36mChatVertexAI._generate_gemini\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_gemini\u001b[39m(\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1184\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1188\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m   1189\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request_gemini(messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1190\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gemini_response_to_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_google_vertexai\\chat_models.py:577\u001b[0m, in \u001b[0;36m_completion_with_retry\u001b[1;34m(generation_method, max_retries, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    572\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    573\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_gemini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[0;32m    576\u001b[0m )\n\u001b[1;32m--> 577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\langchain_google_vertexai\\chat_models.py:570\u001b[0m, in \u001b[0;36m_completion_with_retry.<locals>._completion_with_retry_inner\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry_inner\u001b[39m(generation_method: Callable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\prediction_service\\client.py:2287\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   2284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   2286\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 2287\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2292\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2294\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanle\\Documents\\1d-final-project-summer-2024-sds-2024-team-08\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai."
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool, BaseTool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import rapidfuzz\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import select\n",
    "from PostgreSQLMemorySaver import PostgreSQLMemorySaver\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from models import Alias, Message, Stakeholder, Network_Graph\n",
    "from database import user_engine, stakeholder_engine, media_engine\n",
    "import crud\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "from functools import wraps, partial\n",
    "from typing import List\n",
    "import random\n",
    "from langchain_core.messages import SystemMessage\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def timing_decorator(func):\n",
    "    \"\"\"Decorator that logs the execution time of the function it decorates.\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"{func.__name__} executed in {end_time - start_time:.6f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def use_config(**config_):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return func(*args, config=config_, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def normalize_name(name):\n",
    "    \"\"\"\n",
    "    Normalize names by converting to lowercase, removing special characters except spaces\n",
    "    \"\"\"\n",
    "    name = re.sub(r'[^a-z0-9\\s]', '', name.lower())\n",
    "    return name\n",
    "\n",
    "with Session(stakeholder_engine) as session:\n",
    "    aliases = session.scalars(select(Alias)).all()\n",
    "    aliases_dict = {alias.id: normalize_name(alias.other_names) for alias in aliases}  # Dictionary of id : normalized name\n",
    "    aliases_sid_dict = {alias.id: [alias.stakeholder_id, normalize_name(alias.other_names)] for alias in aliases}  # Dictionary of id : [stakeholder_id, normalized name]\n",
    "\n",
    "@tool\n",
    "# @timing_decorator\n",
    "def read_stakeholders(stakeholder_id: int = None, name: str = None, summary: bool = True, headline: bool = True, photo: bool = True) -> bytes:\n",
    "    \"\"\"Use this tool to read stakeholders from the database. You can filter by stakeholder_id or name. From the prompt, identify the stakeholder by their name or stakeholder_id. \n",
    "    If you are using stakeholder_id, ensure that it is an integer before you input it into the read_stakeholders tool. You can also specify whether to include the summary, headline, and photo.\n",
    "    This tool is used to get summaries and information about stakeholders from the database.\n",
    "\n",
    "    The result returned will be in JSON format.\n",
    "\n",
    "    Args:\n",
    "        stakeholder_id (int, optional): Defaults to None.\n",
    "        name (str, optional): Defaults to None.\n",
    "        summary (bool, optional): Defaults to True.\n",
    "        headline (bool, optional): Defaults to True.\n",
    "        photo (bool, optional): Defaults to True.\n",
    "        \n",
    "    Returns:\n",
    "        str: _description_\n",
    "    \"\"\"\n",
    "    if stakeholder_id is not None:\n",
    "        stakeholder_id = int(float(stakeholder_id))\n",
    "    with Session(stakeholder_engine) as session:\n",
    "        stakeholders = crud.get_stakeholders(session, stakeholder_id, name, summary, headline, photo)\n",
    "\n",
    "    return stakeholders\n",
    "\n",
    "@tool\n",
    "# @timing_decorator\n",
    "def get_name_matches(name: str) -> list:\n",
    "    \"\"\"Use this tool to get the best matches for a given name. This tool will return a list of up to 5 stakeholder_ids who have names that are the best matches with the given name. \n",
    "    If the output only contains one stakeholder_id, then that is the best match. Depending on the context, if the the user wants to know more about the stakeholder, use the tool read_stakeholders tool to get the information about the identified stakeholder.\n",
    "    If the user wants to draw a network graph, use the tool get_relationships to get the relationships of the identified stakeholder.\n",
    "    If the output contains more than one stakeholder_id, then you should ask the user to clarify which stakeholder they are referring to. Following the format :\n",
    "        \"Which names are you referring to?: \n",
    "        1. [name 1]\n",
    "        2. [name 2]\n",
    "        ...\"\n",
    "    If the output contains no names, then there are no matches for the given name.\n",
    "    \n",
    "    Args:\n",
    "        name (str): The name of the stakeholder you want to find matches for.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of up to 5 stakeholder_id who have names that are the best matches with the given name. These stakeolder_id will be integers.\n",
    "    \"\"\"\n",
    "    normalized_input_name = normalize_name(name)\n",
    "    \n",
    "    if normalized_input_name  in aliases_dict.values():\n",
    "        stakeholder_id = [value[0] for value in aliases_sid_dict.values() if value[1] == normalized_input_name]\n",
    "        return stakeholder_id\n",
    "    \n",
    "    else:\n",
    "        best_matches = rapidfuzz.process.extract(normalized_input_name, aliases_dict, score_cutoff=75)  # This wil return a list of tuples with the best matches, their scores and the key. (name, score, id)\n",
    "        \n",
    "        if len(best_matches) == 1:\n",
    "            return [best_matches[0][2]]\n",
    "        \n",
    "        unique_stakeholders = set()\n",
    "        result = []\n",
    "        for match in best_matches:\n",
    "            \n",
    "            if aliases_sid_dict[match[2]][0] not in unique_stakeholders:\n",
    "                unique_stakeholders.add(aliases_sid_dict[match[2]][0])\n",
    "                result.append(match[0])\n",
    "        return result\n",
    "\n",
    "# IN THEORY, the get_names_matches tool will be used to return the stakeholder_id so that it can be run with get_relationships_with_names\n",
    "@tool \n",
    "# @timing_decorator\n",
    "def get_relationships_with_names(subject_id:int = None) -> bytes:\n",
    "    '''\n",
    "    Use this tool to output to the user every relationship the stakeholders have with one another in natural language. This tool should be called when the user wants the relationships of stakeholders in natural language. \n",
    "    This tool will return in JSON format, a list where each element is a list. The format is as such: '[[subject, predicate, object], [subject, predicate, object], ...]'. Where the subject is related to object by the predicate and the subject can have multiple relationships with objects.\n",
    "    If the output is an empty list then it means that the subject has no relationships with the object.\n",
    "\n",
    "    Args:\n",
    "        subject_id (int): The name of the stakeholder you want to find matches for.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of subjects, predicates and objects\n",
    "    '''\n",
    "    subject_id = int(float(subject_id))\n",
    "    with Session(stakeholder_engine) as session:\n",
    "        subject_rs = crud.get_relationships_with_names(session, subject=subject_id)\n",
    "        object_rs = crud.get_relationships_with_names(session, object=subject_id)\n",
    "    if subject_rs == 'No results found.' and object_rs == 'No results found.':\n",
    "        return []\n",
    "    \n",
    "    elif subject_rs == 'No results found.':\n",
    "        return object_rs\n",
    "    \n",
    "    elif object_rs == 'No results found.':\n",
    "        return subject_rs\n",
    "    \n",
    "    return subject_rs + object_rs\n",
    "\n",
    "@tool\n",
    "# @timing_decorator\n",
    "def get_relationships(subject_id:int = None) -> bytes:\n",
    "    '''\n",
    "    Use this tool to get the every relationship the stakeholders have with one another. This tool will be used only if the user wants a network graph. This tool will return in JSON format, a list where each element is a list. The format is as such: '[[subject, predicate, object], [subject, predicate, object], ...]'. Where the subject is related to object by the predicate and the subject can have multiple relationships with objects.\n",
    "    After you have the relationships, you can use the tool generate_network to generate a network graph. The network graph will be generated and stored in the database. Once the graph has been stored, you will need to return the network_graph_id. This id will be used to retrieve the graph from the database.\n",
    "    If the output is an empty list then it means that the subject has no relationships with the object.\n",
    "\n",
    "    Args:\n",
    "        subject_id (int): The name of the stakeholder you want to find matches for.\n",
    "        \n",
    "    Returns:\n",
    "        relationships_with_predicates (list[list[int, str, int]]): A list of subjects, predicates and objects. \n",
    "            The subject is the stakeholder_id of the subject and it is an integer. \n",
    "            The predicate is the relationship between the subject and the object. The predicate is a string. \n",
    "            The object is the stakeholder_id of the object and it is an integer.\n",
    "    '''\n",
    "    # print(\"Getting relationships\")\n",
    "    subject_id = int(float(subject_id))\n",
    "    with Session(stakeholder_engine) as session:\n",
    "        subject_rs = crud.get_relationships(session, subject=subject_id)\n",
    "        object_rs = crud.get_relationships(session, object=subject_id)\n",
    "    \n",
    "    if subject_rs == None and object_rs == None:\n",
    "        return []\n",
    "    \n",
    "    elif subject_rs == None:\n",
    "        relationships = object_rs\n",
    "    \n",
    "    elif object_rs == None:\n",
    "        relationships = subject_rs\n",
    "    \n",
    "    else:    \n",
    "        relationships = subject_rs + object_rs\n",
    "    \n",
    "    relationships_with_predicates = []\n",
    "    for result in relationships:\n",
    "        predicate = result.predicate\n",
    "        extracted_info = crud.extract_after_last_slash(predicate)\n",
    "        extracted_info = re.sub(r'[^a-zA-Z0-9\\' ]', '', extracted_info)\n",
    "        relationships_with_predicates.append((result.subject, extracted_info, result.object))\n",
    "\n",
    "    return relationships_with_predicates\n",
    "\n",
    "def get_photo(stakeholder_id: int) -> str:\n",
    "    stakeholder_id = int(stakeholder_id)\n",
    "    with Session(stakeholder_engine) as session:\n",
    "        response = session.scalars(select(Stakeholder).where(Stakeholder.stakeholder_id == stakeholder_id).limit(1)).one_or_none()\n",
    "        if response is not None:\n",
    "            ref_pic = response.photo\n",
    "            if ref_pic:\n",
    "                pic_url = ref_pic.split(\"||\")[0].strip()  # Split by \"||\" and take the first URL\n",
    "                return pic_url\n",
    "            else:\n",
    "                print(f\"No photo field for get_photo({stakeholder_id}): {response}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"stakeholder {stakeholder_id} does not exist\")\n",
    "            return None\n",
    "\n",
    "g_id = {}  # Dictionary to store the generated network graph id a global dictionary\n",
    "def generate_tools(chat_id: int) -> List[BaseTool]:\n",
    "    \"\"\"Generate a set of tools that have a chat_id associated with them.\"\"\"\n",
    "    \n",
    "    @tool\n",
    "    # @timing_decorator\n",
    "    def generate_network(relationships: list[list[str]]) -> dict:\n",
    "        \"\"\"You need to consider the predicates in each of the relationships and identify the appropriate ones only based on the user input. If the user did not mention any specific context, then you can consider all the relationships. \n",
    "        You can use this tool to generate the network graph. The network graph will be generated and stored in the database. Once the graph has been stored, you will need to return the network_graph_id. This id will be used to retrieve the graph from the database.\n",
    "        This tool will be called when the user mentions that they want a visualisation or if they want to draw a network graph or simply a graph.\n",
    "        \n",
    "        Args:\n",
    "            relationships (list): A list where each element is a list. The format is as such: '[[subject, predicate, object], [subject, predicate, object], ...]'. Where the subject is related to object by the predicate and the subject can have multiple relationships with objects.\n",
    "            \n",
    "        Returns:\n",
    "            results (str): A JSON object containing the message 'network graph has been created.'\n",
    "        \"\"\"\n",
    "        # print(\"generating network\")\n",
    "        # print(relationships)\n",
    "        subj_color=\"#77E4C8\"\n",
    "        obj_color=\"#3DC2EC\"\n",
    "        edge_color=\"#96C9F4\"\n",
    "        subj_shape=\"image\"\n",
    "        obj_shape=\"image\"\n",
    "        buttons = False\n",
    "        g = Network(height=\"1024px\", width=\"100%\",font_color=\"black\")\n",
    "        # if buttons == True:\n",
    "        #     g.width = \"75%\"\n",
    "        #     g.show_buttons(filter_=[\"edges\", \"physics\"])\n",
    "        # print(buttons)\n",
    "        with Session(stakeholder_engine) as db:\n",
    "            lvl = 0\n",
    "            for rs in relationships:\n",
    "                # for rs in rss:\n",
    "                subject_id = int(float(rs[0]))\n",
    "                subj = crud.get_stakeholder_name(db, subject_id)\n",
    "                pred = rs[1]\n",
    "                object_id = int(float(rs[2]))\n",
    "                obj = crud.get_stakeholder_name(db, object_id)\n",
    "                s_pic = get_photo(subject_id)\n",
    "                o_pic = get_photo(object_id)\n",
    "                g.add_node(subj, color=subj_color, shape=subj_shape, image=s_pic, size=40, level=lvl, x=lvl, y=lvl)\n",
    "                g.add_node(obj, color=obj_color, shape=obj_shape, image=o_pic, size=20, level=lvl+1, x=(lvl+1)*random.randint(5,10), y=(lvl+1)*random.randint(5,10))\n",
    "                g.add_edge(subj,obj,label=pred, color=edge_color, smooth=False)\n",
    "            lvl += 1\n",
    "\n",
    "        g.repulsion(node_distance=250, spring_length=350)\n",
    "        g.set_edge_smooth(\"dynamic\")\n",
    "        network_graph = g.generate_html()\n",
    "        \n",
    "        with Session(user_engine) as session:\n",
    "            graph = Network_Graph()\n",
    "            graph.content = network_graph\n",
    "            graph.chat_id = chat_id\n",
    "            \n",
    "            session.add(graph)\n",
    "            session.commit()\n",
    "            generated_id = graph.id\n",
    "        g_id[chat_id] = generated_id\n",
    "\n",
    "        return {\"message\": \"Network graph has been created!\"}\n",
    "    \n",
    "    return [generate_network]\n",
    "\n",
    "def query_model(query:str, user_id:int, chat_id:int) -> str:\n",
    "    \"\"\"\n",
    "    Call this function from outside the module\n",
    "    \"\"\"\n",
    "\n",
    "    with Session(user_engine) as s:\n",
    "        message = Message()\n",
    "        message.chat_id = chat_id\n",
    "        message.content = query\n",
    "        message.sender_id = user_id\n",
    "        message.role = 'user'\n",
    "\n",
    "        s.add(message)\n",
    "        s.commit()\n",
    "\n",
    "    model = ChatVertexAI(model=\"gemini-1.5-flash\", max_retries=2)\n",
    "\n",
    "    ls = [read_stakeholders, get_name_matches, get_relationships, get_relationships_with_names]\n",
    "    \n",
    "    tools = ls + generate_tools(chat_id=chat_id)\n",
    "    messages_modifier = \"\"\"\n",
    "    # Instructions for the system\n",
    "    ## 1. Overview\n",
    "    You are a top-tier algorithm designed for extracting information from our databases to provide users with information about stakeholders if they are present in the database. \n",
    "    You are able to present the response as text and you are able to generate a network graph based on the relationships of the stakeholders if requested to. \n",
    "    You must capture the user's input and provide the appropriate response based on the user's query. \n",
    "    The aim is to provide the user with the most relevant information based on the user's query.\n",
    "    ## 2. Stakeholders\n",
    "    When a user asks for information about a stakeholder, you must extract the stakeholder's name from the user's query and use it to extract stakeholder information from the database. \n",
    "    You can use these tools to help you identify the appropriate stakeholder: read_stakeholders, get_name_matches.\n",
    "    If you require more information from the user, you can ask the user to clarify which stakeholder they are referring to.\n",
    "    ## 3. Relationships\n",
    "    When a user asks for relationships between stakeholders, you must extract the context from the user's query and use it to filter out or filter in relationships based on the context by evaluating the predicate of each relationship.\n",
    "    You can use these tools to help you identify the appropriate relationships: get_relationships, get_relationships_with_names.\n",
    "    If you deem that the relationships are not relevant to the context from the user's query, you will remove those relationships as well.\n",
    "    ## 4. Network Graph\n",
    "    When a user asks for a network graph, you must generate a network graph based on the relationships of the stakeholders that you have identified.\n",
    "    You can use these tools to help you generate the network graph: generate_network.\n",
    "    Once you have generated the network graph, you will store the graph in the database and return 'The network graph has been created!' to the user.\n",
    "    ## 5. Strict Compliance\n",
    "    Adhere to the rules strictly and ensure that you are providing the most relevant information to the user based on the user's query. Non-compiance will result in termination.\n",
    "    \"\"\"\n",
    "    graph = create_react_agent(model, tools=tools, messages_modifier=SystemMessage(content=messages_modifier), checkpointer=PostgreSQLMemorySaver(engine=user_engine))\n",
    "    inputs = {\"messages\": [\n",
    "        (\"user\", query)\n",
    "        ]}\n",
    "    \n",
    "    config = {\n",
    "        'configurable': {'thread_id': chat_id}\n",
    "    }\n",
    "    \n",
    "    response = graph.invoke(inputs, config=config, stream_mode=\"updates\") #Stream mode set to updates instead of values for less verbosity\n",
    "    response_str = response[-1]['agent']['messages'][-1].content\n",
    "            \n",
    "    #  insert graph shit into Messages \n",
    "    with Session(user_engine) as s:\n",
    "        message = Message()\n",
    "        message.chat_id = chat_id\n",
    "        message.content = response_str\n",
    "        message.sender_id = 1\n",
    "        message.role = 'assistant'\n",
    "        if chat_id in g_id:\n",
    "            message.network_graph_id = g_id[chat_id]\n",
    "            del g_id[chat_id]        \n",
    "        s.add(message)\n",
    "        s.commit()\n",
    "\n",
    "    return response_str\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(query_model(\"Generate a network graph to show the relationships Joe Biden has. Exclude all the relationships that includes stakeholders giving Joe Biden grants.\", 3, 10))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool, BaseTool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import rapidfuzz\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import select\n",
    "from PostgreSQLMemorySaver import PostgreSQLMemorySaver\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from models import Alias, Message, Stakeholder, Network_Graph\n",
    "from database import user_engine, stakeholder_engine, media_engine\n",
    "import crud\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "from functools import wraps, partial\n",
    "from typing import List, Literal\n",
    "import random\n",
    "from langchain_core.messages import SystemMessage\n",
    "import time\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_core.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "parameter without a default follows parameter with a default (3526432815.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    def create_agent(llm, tools, checkpointer: Optional[BaseCheckpointSaver] = None, system_message: str):\u001b[0m\n\u001b[1;37m                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m parameter without a default follows parameter with a default\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "def create_agent(llm, tools, system_message: str, checkpointer: Optional[BaseCheckpointSaver] = None):\n",
    "    \"\"\"Create a base agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_tools(tools)\n",
    "  \n",
    "  # Helper function to create a node for a given agent\n",
    "def agent_node(state, agent, name):\n",
    "    \"\"\"create a base node for a given agent\"\"\"\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from langchain_core.messages import AIMessage# Research agent and node\n",
    "\n",
    "# @tool\n",
    "# def graph_master_tool(): #! temp implementation\n",
    "#   \"\"\"placeholder for graph master tool\"\"\"\n",
    "#   return None\n",
    "\n",
    "model = ChatVertexAI(model=\"gemini-1.5-flash\", max_retries=2)\n",
    "researcher_tools = [read_stakeholders, get_name_matches, get_relationships, get_relationships_with_names]\n",
    "graph_master_tools = [generate_tools]  #! temp implementation\n",
    "researcher_agent = create_agent( #creating agent that has tailored system prompt & tools\n",
    "    llm = model,\n",
    "    tools = researcher_tools,\n",
    "    system_message=\"\"\"\n",
    "    # Instructions for the system\n",
    "    ## 1. Overview\n",
    "    You are a top-tier algorithm designed for extracting information from our databases to provide users with information about stakeholders if they are present in the database. \n",
    "    \n",
    "    You are able to present the response as text and you are able to generate a network graph based on the relationships of the stakeholders if requested to. \n",
    "    You must capture the user's input and provide the appropriate response based on the user's query. \n",
    "    \n",
    "    The aim is to provide the user with the most relevant information based on the user's query.\n",
    "    \n",
    "    ## 2. Stakeholders\n",
    "    When a user asks for information about a stakeholder, you must extract the stakeholder's name from the user's query and use it to extract stakeholder information from the database. \n",
    "    You can use these tools to help you identify the appropriate stakeholder: read_stakeholders, get_name_matches.\n",
    "    If you require more information from the user, you can ask the user to clarify which stakeholder they are referring to.\n",
    "    \n",
    "    ## 3. Relationships\n",
    "    When a user asks for relationships between stakeholders, you must extract the context from the user's query and use it to filter out or filter in relationships based on the context by evaluating the predicate of each relationship.\n",
    "    You can use these tools to help you identify the appropriate relationships: get_relationships, get_relationships_with_names.\n",
    "    If you deem that the relationships are not relevant to the context from the user's query, you will remove those relationships as well.\n",
    "    \n",
    "    \n",
    "    If you are unable to fully answer, that's OK, another assistant with different tools will help where you left off. Execute what you can to make progress.If you or any of the other assistants have the final answer or deliverable, prefix your response with FINAL ANSWER so the team knows to stop.\n",
    "    \n",
    "    ## 4. Network Graph\n",
    "    When a user asks for a network graph, you must generate a list of lists based on the relationships of the stakeholders that you have identified. Use the generate_network tool to generate the network graph.\n",
    "   \n",
    "    \n",
    "    ## 5. Strict Compliance\n",
    "    Adhere to the rules strictly and ensure that you are providing the most relevant information to the user based on the user's query. Non-compiance will result in termination.\n",
    "    \"\"\",\n",
    "    checkpointer=PostgreSQLMemorySaver(engine=user_engine),\n",
    ")\n",
    "\n",
    "graph_master_agent = create_agent( #creating agent that has tailored system prompt & tools\n",
    "    llm = model,\n",
    "    tools = [read_stakeholders, get_name_matches, get_relationships, get_relationships_with_names],\n",
    "    system_message=\"\"\"generate graph here, not done\"\"\",\n",
    "    checkpointer=PostgreSQLMemorySaver(engine=user_engine),\n",
    ")\n",
    "\n",
    "\n",
    "researcher_node = functools.partial(agent_node, agent=researcher_agent, name=\"researcher\")\n",
    "graph_master_node = functools.partial(agent_node, agent=graph_master_agent, name=\"graph Master\")\n",
    "\n",
    "#creating a node for researcher_agent to send messages around to other nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = researcher_tools + graph_master_tools\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Either agent can decide to end\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
    "    # This is the router\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        # The previous agent is invoking a tool\n",
    "        return \"call_tool\"\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return \"__end__\"\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str\n",
    "    \n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"researcher\", researcher_node)\n",
    "workflow.add_node(\"graph_master\", graph_master_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"researcher\",\n",
    "    router,\n",
    "    {\"continue\": \"graph_master\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"graph_master\",\n",
    "    router,\n",
    "    {\"continue\": \"researcher\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    # Each agent node updates the 'sender' field\n",
    "    # the tool calling node does not, meaning\n",
    "    # this edge will route back to the original agent\n",
    "    # who invoked the tool\n",
    "    lambda x: x[\"sender\"],\n",
    "    {\n",
    "        \"researcher\": \"researcher\",\n",
    "        \"graph_master\": \"graph_master\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(START, \"researcher\")\n",
    "graph = workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'researcher': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_name_matches', 'arguments': '{\"name\": \"ben carson\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_LOW'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 2458, 'candidates_token_count': 9, 'total_token_count': 2467}}, name='researcher', id='run-fcea294e-77cb-4908-8174-6a35b80de50f-0', tool_calls=[{'name': 'get_name_matches', 'args': {'name': 'ben carson'}, 'id': '09d7c4ba-96ba-474d-bb52-37b1c8eefb98', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2458, 'output_tokens': 9, 'total_tokens': 2467})], 'sender': 'researcher'}}\n",
      "{'call_tool': {'messages': [ToolMessage(content='[1]', name='get_name_matches', tool_call_id='09d7c4ba-96ba-474d-bb52-37b1c8eefb98')]}}\n",
      "{'researcher': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_relationships', 'arguments': '{\"subject_id\": 1.0}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 2476, 'candidates_token_count': 6, 'total_token_count': 2482}}, name='researcher', id='run-8065159b-a20d-4186-a608-235906977f6a-0', tool_calls=[{'name': 'get_relationships', 'args': {'subject_id': 1.0}, 'id': '924c91ac-4149-4d7e-a1fb-b6d6ead3ff8b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2476, 'output_tokens': 6, 'total_tokens': 2482})], 'sender': 'researcher'}}\n",
      "{'call_tool': {'messages': [ToolMessage(content='[[1, \"MBA in Psychology\", 29155], [1, \"Director\", 3656], [1, \"Education\", 29155]]', name='get_relationships', tool_call_id='924c91ac-4149-4d7e-a1fb-b6d6ead3ff8b')]}}\n",
      "{'researcher': {'messages': [AIMessage(content=\"FINAL ANSWER: Ben Carson has a few relationships. Ben Carson has an MBA in Psychology and an Education relationship with  Stakeholder 29155. Ben Carson is the Director of Stakeholder 3656. I can't make a network graph for you at the moment, but maybe another assistant could. \\n\", response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 2526, 'candidates_token_count': 67, 'total_token_count': 2593}}, name='researcher', id='run-185a820e-dff5-4945-b33e-913e34af0cc7-0', usage_metadata={'input_tokens': 2526, 'output_tokens': 67, 'total_tokens': 2593})], 'sender': 'researcher'}}\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"tell me about ben carson's relationships, make me a graph on it\"\n",
    "\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 150},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
